<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>coding | small DATA</title><link>https://smalldata.github.io/tag/coding/</link><atom:link href="https://smalldata.github.io/tag/coding/index.xml" rel="self" type="application/rss+xml"/><description>coding</description><generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Fri, 18 Sep 2020 00:00:00 +0000</lastBuildDate><image><url>https://smalldata.github.io/images/icon_hu137b7eee8aa8b920cff43510025d0585_16891_512x512_fill_lanczos_center_3.png</url><title>coding</title><link>https://smalldata.github.io/tag/coding/</link></image><item><title>Getting stats on browsing history from the browser database</title><link>https://smalldata.github.io/posts/browsing-stats/</link><pubDate>Fri, 18 Sep 2020 00:00:00 +0000</pubDate><guid>https://smalldata.github.io/posts/browsing-stats/</guid><description>&lt;p>If you didn&amp;rsquo;t know, there are more SQLite databases in the universe (
&lt;a href="https://www.sqlite.org/mostdeployed.html" target="_blank" rel="noopener">1+ trillion&lt;/a>) than there are known galaxies (
&lt;a href="https://www.discovermagazine.com/the-sciences/how-many-galaxies-are-there-astronomers-are-revealing-the-enormity-of-the" target="_blank" rel="noopener">100 billion&lt;/a>). And one of those SQLite databases happens to be your browsing history. As a short proof-of-concept, here&amp;rsquo;s how to access the history of your Firefox browser via the SQLite database.&lt;/p>
&lt;h2 id="find-your-database-file">find your database file&lt;/h2>
&lt;p>Mozilla Firefox stores your cookies, bookmarks, form inputs, and browsing history under the path defined in your profile settings. To find the path of those files in your file system, visit &lt;strong>about:profiles&lt;/strong> in a Firefox window.&lt;/p>
&lt;p>In my case, I only use really one profile, which is shown in the orange box.&lt;/p>
&lt;p>&lt;img src="https://smalldata.github.io/images/firefox-profile-path.png" alt="showing file system path to profile in firefox">&lt;/p>
&lt;p>You can click &amp;ldquo;Show in Finder&amp;rdquo; and then scroll down to the file &lt;code>places.sqlite&lt;/code>. Trying to directly open this database file gives the error &amp;ldquo;locked database&amp;rdquo; &amp;ndash; you&amp;rsquo;ll need to make a copy of the file in a different folder before opening.&lt;/p>
&lt;p>&lt;img src="https://smalldata.github.io/images/firefox-db-locked.png" alt="database is locked">&lt;/p>
&lt;h2 id="explore-the-database">explore the database&lt;/h2>
&lt;p>The go-to SQLite client is
&lt;a href="https://sqlitebrowser.org/" target="_blank" rel="noopener">DB Browser for SQLite&lt;/a>. Once installed, you can easily open your &lt;code>places.sqlite&lt;/code> file with &amp;ldquo;Open With&amp;rdquo; from Finder.&lt;/p>
&lt;p>&lt;img src="https://smalldata.github.io/images/firefox-db-openwith.png" alt="opening the db file">&lt;/p>
&lt;p>Once the database file is open, you&amp;rsquo;ll see 13 tables&lt;/p>
&lt;p>&lt;img src="https://smalldata.github.io/images/firefox-db-tables.png" alt="finding the right tables">&lt;/p>
&lt;p>After digging through a couple tables, the one with your browsing history is called &lt;code>moz_places&lt;/code>. By viewing this table, you&amp;rsquo;ll see that the field &lt;code>url&lt;/code> stores the page visited, and last visit date is the UNIX timestamp of the last visit.&lt;/p>
&lt;p>&lt;img src="https://smalldata.github.io/images/firefox-db-history-view.png" alt="viewing the table with browsing history">&lt;/p>
&lt;p>Sort descending by &lt;code>visit_count&lt;/code> and you&amp;rsquo;ll find your most commonly viewed website. For me, it&amp;rsquo;s HackerNews, and then various permutations of Twitter. (I use the mobile Twitter site instead of the app, and I sync my history between devices.)&lt;/p>
&lt;h2 id="query-the-database">query the database&lt;/h2>
&lt;p>Despite using Twitter, I&amp;rsquo;m a private person, and I don&amp;rsquo;t want to share any real analysis of my browsing history. I do want to share one result: the distribution of &lt;code>http://localhost&lt;/code> ports. Here&amp;rsquo;s a short python3 script that reads the copy of the &lt;code>place.sqlite&lt;/code> file, and returns a count of localhost ports from the browsing history.&lt;/p>
&lt;pre>&lt;code class="language-python">import pandas as pd
import sqlite3
# connect and read database
con = sqlite3.connect('places.sqlite')
df = pd.read_sql_query('select * from moz_places', con)
con.close()
#Â filter for urls containing localhost
# notice I include ':', which means a port should be defined
df = df[df.url.str.contains('localhost:',case=False)]
# parse the url to get just the port
df.port = df.url.str.split(':').str[-1].str.split('/').str[0]
# keep only port column and do a count by grouping each port
df = df.port
df = df.groupby(df).count()
print(df.to_markdown())
&lt;/code>&lt;/pre>
&lt;p>Here&amp;rsquo;s the results, with my annotation:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:left">port&lt;/th>
&lt;th style="text-align:center">count&lt;/th>
&lt;th style="text-align:left">description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:left">1313&lt;/td>
&lt;td style="text-align:center">144&lt;/td>
&lt;td style="text-align:left">Hugo devserver - this site!&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">3000&lt;/td>
&lt;td style="text-align:center">41&lt;/td>
&lt;td style="text-align:left">Metabase (?), which I tested a while ago&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">5000&lt;/td>
&lt;td style="text-align:center">4&lt;/td>
&lt;td style="text-align:left">Flask web server (work stuff)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">50222&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:left">Callback for Tableau authentication&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">58595&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:left">Not sure, but probably similar to 50222&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">8000&lt;/td>
&lt;td style="text-align:center">137&lt;/td>
&lt;td style="text-align:left">Old faithful, in this case mkdocs (work stuff)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">8888&lt;/td>
&lt;td style="text-align:center">37&lt;/td>
&lt;td style="text-align:left">Jupyter notebook server&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">8889&lt;/td>
&lt;td style="text-align:center">4&lt;/td>
&lt;td style="text-align:left">Jupyter notebook server&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">9005&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:left">Callback for Firebase CLI authentication&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">&lt;/td>
&lt;td style="text-align:center">7&lt;/td>
&lt;td style="text-align:left">No port means URL had multiple &lt;code>:&lt;/code>. See below.&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>Similar aggregation could be done directly in SQL:&lt;/p>
&lt;pre>&lt;code class="language-sql">select
port,
count(1)
from
(
select
url,
replace( replace( substr(url, instr(url, 'localhost:'), 15), 'localhost:' , ''), '/', '') as port
from
moz_places
where
url like '%localhost:%'
)
group by
port
&lt;/code>&lt;/pre>
&lt;p>which generates &lt;em>almost&lt;/em> identical results.&lt;/p>
&lt;p>The SQL query picked up one instance of &lt;code>localhost:9005&lt;/code> that the Python script didn&amp;rsquo;t find.&lt;/p>
&lt;p>Digging deeper:&lt;/p>
&lt;pre>&lt;code class="language-sql">select
*
from
moz_places
where
url like '%localhost:9005%'
&lt;/code>&lt;/pre>
&lt;p>shows that port 9005 was used for the Callback on Firebase CLI authentication. The reason is because the Python script splits on the &lt;code>:&lt;/code> character, for which this URL has more than one. The table shows 7 localhost URLs without ports, but these are actually URLs that have more than one &lt;code>:&lt;/code> character. I&amp;rsquo;ve updated the table above, but not the Python script.&lt;/p>
&lt;h2 id="conclusion">conclusion&lt;/h2>
&lt;p>Everything is a SQLite database.&lt;/p></description></item><item><title>Generating folders with smart dates in Python + Pandas</title><link>https://smalldata.github.io/posts/python-date-folders/</link><pubDate>Mon, 31 Aug 2020 00:00:00 +0000</pubDate><guid>https://smalldata.github.io/posts/python-date-folders/</guid><description>&lt;blockquote>
&lt;p>&lt;em>Not everything your mother told you is true.&lt;/em>&lt;/p>
&lt;/blockquote>
&lt;p>&lt;small>&amp;ndash;my CompSci 101 professor, when a student &lt;em>insisted&lt;/em> that, without exception, every 4th year was a leap year&lt;/small>&lt;/p>
&lt;hr>
&lt;h3 id="the-idea">the idea&lt;/h3>
&lt;p>For a hobby project, I needed to generate thousands folders and sub-folders and sub-sub-folders based on calendar dates within a range.&lt;/p>
&lt;p>This means, I wanted to have a main folder, called something like &lt;code>tmp_dates/&lt;/code>. In that folder, I wanted to have sub-folders for each year within a range: &lt;code>tmp_dates/2020/&lt;/code>. And sub-folders for months: &lt;code>tmp_dates/2020/06/&lt;/code>. And sub-folders for days: &lt;code>tmp_dates/2020/06/30&lt;/code>.&lt;/p>
&lt;h3 id="smart-calendar-dates-and-leap-years">smart calendar dates and leap years&lt;/h3>
&lt;p>Using Python&amp;rsquo;s standard &lt;code>datetime&lt;/code> library, I can easily generate date ranges with &lt;code>timedelta()&lt;/code>. This is necessary for generating &amp;ldquo;smart&amp;rdquo;-dates that take into account varying days per month, as well as those pesky leap years. It turns out that the
&lt;a href="https://en.wikipedia.org/wiki/Leap_year#Algorithm" target="_blank" rel="noopener">rules for leap years&lt;/a> are &lt;strong>not&lt;/strong> as simple as years that are multiples of 4. &lt;small>Sadly, for those of us born in the late 20th Century, we won&amp;rsquo;t be alive to see a year divisible by 4 that is &lt;em>not&lt;/em> a leap year. The next one of those is year &lt;code>2100&lt;/code>. The year &lt;code>2000&lt;/code> was a leap year despite being divisible by 100 because it was also divisible by 400.&lt;/small>&lt;/p>
&lt;p>Wrapping the date-range functionality with Pandas makes the code extremely efficient. Here&amp;rsquo;s an adapted
&lt;a href="https://stackoverflow.com/a/59882807/2327328" target="_blank" rel="noopener">StackOverflow snippet&lt;/a> which does the heavy lifting.&lt;/p>
&lt;pre>&lt;code class="language-python">import pandas as pd
from datetime import date, timedelta
sdate = date(2000,1,1) # start date
edate = date.today() # end date
df = pd.date_range(sdate,edate-timedelta(days=1),freq='d')
&lt;/code>&lt;/pre>
&lt;h3 id="generating-sub-folders-based-on-a-date-range">generating (sub-)folders based on a date range&lt;/h3>
&lt;p>In addition to generating the date-folders, I want my code to create folders but not overwrite files if a folder exists. For this I used
&lt;a href="https://stackoverflow.com/a/273227/2327328" target="_blank" rel="noopener">this snippet&lt;/a> that uses the wonderful new Python3 library
&lt;a href="https://docs.python.org/3/library/pathlib.html" target="_blank" rel="noopener">&lt;code>pathlib.Path()&lt;/code>&lt;/a> to create a folder called &lt;code>tmp_dates/&lt;/code> in the current working directory. If that folder already exists, it will otherwise ignored.&lt;/p>
&lt;pre>&lt;code class="language-python">from pathlib import Path
Path('tmp_dates/').mkdir(parents=True, exist_ok=True)
&lt;/code>&lt;/pre>
&lt;h3 id="adding-an-empty-file-to-each-folder">adding an empty file to each folder&lt;/h3>
&lt;p>Git can&amp;rsquo;t handle an empty directory. To include empty directories, on Github at least, there is an
&lt;a href="https://stackoverflow.com/a/7229996/2327328" target="_blank" rel="noopener">undocumented feature&lt;/a> where an empty folder that has the empty file &lt;code>.gitkeep&lt;/code> will be included in the version control. The &lt;code>pathlib.Path()&lt;/code> library can even create an empty file, using the
&lt;a href="https://docs.python.org/3/library/pathlib.html#pathlib.Path.touch" target="_blank" rel="noopener">&lt;code>.touch()&lt;/code>&lt;/a> function, which copies its functionality from the
&lt;a href="https://en.wikipedia.org/wiki/Touch_%28command%29#Overview" target="_blank" rel="noopener">Unix touch command&lt;/a>.&lt;/p>
&lt;pre>&lt;code class="language-python">from pathlib import Path
Path('tmp_dates/').mkdir(parents=True, exist_ok=True)
Path('tmp_dates/'+os.sep+'.gitkeep').touch()
&lt;/code>&lt;/pre>
&lt;h3 id="putting-it-all-together">putting it all together&lt;/h3>
&lt;p>All that&amp;rsquo;s left is to combine all the pieces into one Python3 script that safely generates sub-folders for individual calendar dates in a date range.&lt;/p>
&lt;pre>&lt;code class="language-python">from datetime import date, timedelta
import pandas as pd
from pathlib import Path #requires Python&amp;gt;=3.5
import os
# safe generate folders for all dates within a range
def create_folder(p):
Path(p).mkdir(parents=True, exist_ok=True)
Path(p+os.sep+'.gitkeep').touch()
# where to start to put the many folders
subpath = 'tmp_dates'
# start and end date
sdate = date(2000,1,1) # start date
edate = date.today() # end date
# use pandas for the heavy lifting of building the calendar-aware date range
df = pd.date_range(sdate,edate-timedelta(days=1),freq='d')
# loop over all values and create a folder for each possible date
for d in df:
#print(d.year, d.month, d.day)
path = subpath + os.sep + str(d.year).zfill(4) + os.sep + str(d.month).zfill(2) + os.sep + str(d.day).zfill(2)
create_folder(path)
#break # debugging
&lt;/code>&lt;/pre></description></item><item><title>Fun with Favicons</title><link>https://smalldata.github.io/posts/favicon-mosaic/</link><pubDate>Wed, 17 Apr 2019 00:00:00 +0000</pubDate><guid>https://smalldata.github.io/posts/favicon-mosaic/</guid><description>&lt;p>A recent
&lt;a href="https://opendata.stackexchange.com/q/14007/1511" target="_blank" rel="noopener">question&lt;/a> on the Open Data Stack Exchange site got me thinking about how to download favicons from a bulk list of websites.&lt;/p>
&lt;h3 id="idea-1-try-each-domain">Idea 1: try each domain&lt;/h3>
&lt;p>Something like &lt;code>http://example.com/favicon.ico&lt;/code>. But using a &lt;code>favicon.ico&lt;/code> in the webroot folder is just a common implementation. Each website can host their favicon with another path, and another file format.&lt;/p>
&lt;p>Let&amp;rsquo;s try something else&amp;hellip;&lt;/p>
&lt;h3 id="idea-2-parse-html-for-favicon-urls">Idea 2: parse html for favicon urls&lt;/h3>
&lt;p>If the website doesn&amp;rsquo;t use &lt;code>favicon.ico&lt;/code> in the webroot folder, the page html will contain a path to the favicon, with the following format:&lt;/p>
&lt;pre>&lt;code>&amp;lt;link rel=icon href=https://smalldata.github.io/favicon.png&amp;gt;
&lt;/code>&lt;/pre>
&lt;p>There is python package aptly named
&lt;a href="https://github.com/scottwernervt/favicon" target="_blank" rel="noopener">favicon&lt;/a> that will parse the html and return the urls to all favicons, with different formats and resolutions. I&amp;rsquo;m pasting their demo code here:&lt;/p>
&lt;pre>&lt;code class="language-python">&amp;gt;&amp;gt;&amp;gt; import favicon
&amp;gt;&amp;gt;&amp;gt; icons = favicon.get('https://www.python.org/')
Icon(url='https://www.python.org/static/apple-touch-icon-144x144-precomposed.png', width=144, height=144, format='png')
Icon(url='https://www.python.org/static/apple-touch-icon-114x114-precomposed.png', width=114, height=114, format='png')
Icon(url='https://www.python.org/static/apple-touch-icon-72x72-precomposed.png', width=72, height=72, format='png')
Icon(url='https://www.python.org/static/apple-touch-icon-precomposed.png', width=0, height=0, format='png')
Icon(url='https://www.python.org/static/favicon.ico', width=0, height=0, format='ico')
&lt;/code>&lt;/pre>
&lt;p>Getting better&amp;hellip; But if I download bulk favicons, I&amp;rsquo;d like to avoid normalizing their file format and resolutions.&lt;/p>
&lt;h3 id="idea-3-get-favicons-directly-from-googles-cache">Idea 3: get favicons directly from google&amp;rsquo;s cache&lt;/h3>
&lt;p>Google keeps the favicon cached for many sites (even my little website with basically zero traffic).&lt;/p>
&lt;pre>&lt;code>https://www.google.com/s2/favicons?domain=apache.org
&lt;/code>&lt;/pre>
&lt;p>And the favicons are all normalized: 16x16 pixels and png format. Perfect.&lt;/p>
&lt;h2 id="now-for-some-fun">Now for some fun&lt;/h2>
&lt;p>A
&lt;a href="https://moz.com/top500" target="_blank" rel="noopener">top500 website list&lt;/a> has a
&lt;a href="https://web.archive.org/web/20150226044534/http://moz.com:80/top500/domains/csv" target="_blank" rel="noopener">csv export&lt;/a> and wrote a Python script to download each of these 500 favicons from Google&amp;rsquo;s cache and save to local folder &lt;code>images/&lt;/code>.&lt;/p>
&lt;pre>&lt;code>import requests
import pandas as pd
import os
from io import StringIO
def request_function(domain):
domain = domain.replace('/','')
url = 'https://www.google.com/s2/favicons?domain=' + domain
fav = requests.get(url).content
with open('images'+os.sep+domain+'.png', 'wb') as handler:
handler.write(fav)
return
# top 500 websites from mozilla https://moz.com/top500
url = &amp;quot;https://web.archive.org/web/20150226044534/http://moz.com:80/top500/domains/csv&amp;quot;
headers = {&amp;quot;User-Agent&amp;quot;: &amp;quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:66.0) Gecko/20100101 Firefox/66.0&amp;quot;}
req = requests.get(url, headers=headers)
data = StringIO(req.text)
df = pd.read_csv(data)
df.URL.apply(request_function)
&lt;/code>&lt;/pre>
&lt;h3 id="favicon-art">Favicon art&lt;/h3>
&lt;p>What to do with 500 favicons. For fun, I made a mosaic from the collection, and I first needed a original piece of art that would be recongnizable when heavily pixelated. Van Gogh&amp;rsquo;s
&lt;a href="https://en.wikipedia.org/wiki/The_Starry_Night" target="_blank" rel="noopener">Starry night&lt;/a> stood out.&lt;/p>
&lt;p>Here&amp;rsquo;s the original:&lt;/p>
&lt;p>&lt;img src="https://smalldata.github.io/images/1137px-Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg" alt="Starry Night">&lt;/p>
&lt;p>&lt;em>Source&lt;/em>:
&lt;a href="https://en.wikipedia.org/wiki/The_Starry_Night#/media/File:Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg" target="_blank" rel="noopener">Wikipedia&lt;/a>&lt;/p>
&lt;p>Then I used a handy Python script called
&lt;a href="https://github.com/codebox/mosaic" target="_blank" rel="noopener">mosaic.py&lt;/a>. No coding necessary.&lt;/p>
&lt;pre>&lt;code>git clone https://github.com/codebox/mosaic.git
python mosaic/mosaic.py source.jpg images/
&lt;/code>&lt;/pre>
&lt;p>And what pops out is a &lt;em>Starry Night of Favicons&lt;/em>.&lt;/p>
&lt;p>&lt;img src="https://smalldata.github.io/images/mosaic.jpeg" alt="Favicon Starry Night">&lt;/p>
&lt;hr>
&lt;p>(full resolution download:
&lt;a href="https://smalldata.github.io/images/mosaic_full.jpeg">22 MB&lt;/a>)&lt;/p>
&lt;p>(python
&lt;a href="https://gist.github.com/philshem/e59388197fd9ddb7dcdb8098f9f0aaf2" target="_blank" rel="noopener">source code&lt;/a>)&lt;/p>
&lt;p>(top500 favicons:
&lt;a href="https://smalldata.github.io/images/top500_favicons.zip">zip&lt;/a>)&lt;/p></description></item></channel></rss>